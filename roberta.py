# -*- coding: utf-8 -*-
"""3_Roberta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRJyXGlC6nRHN-nIFwmaU1A2mjB1I7Yb
"""

!pip install datasets
!pip install torch
!pip install evaluate
!pip install stop_words
!pip install datasets imbalanced-learn

!python -m spacy download ru_core_news_sm
!python -m spacy download fi_core_news_sm
!python -m spacy download ja_core_news_sm

#Dont know why this is coming up for me
import os
os.environ["WANDB_MODE"] = "disabled"

!pip uninstall wandb

#imports
import pandas as pd
import datasets
from datasets import Dataset
from datasets import load_dataset
import evaluate
import numpy as np
import nltk
from tqdm.notebook import tqdm
import spacy
from transformers import BertTokenizer
from transformers import pipeline, Trainer, TrainingArguments
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.metrics import mean_squared_error
import torch
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
import re
import stop_words
from sklearn.metrics import confusion_matrix, classification_report

# Placing the model on the GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

#Loading dataset
ds = load_dataset("coastalcph/tydi_xor_rc")
train = ds['train']
validation = ds['validation']

# Seperating by languages

# Training: Seperating by language
train_ru_df = train.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'ru')
train_ja_df = train.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'ja')
train_fi_df = train.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'fi')
train_en_df = train.select_columns([ 'context','lang', 'answerable'])

# Testing
val_ru_df = validation.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'ru')
val_ja_df = validation.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'ja')
val_fi_df = validation.select_columns(['question', 'context','lang', 'answerable']).filter(lambda x: x['lang'] == 'fi')
val_en_df = validation.select_columns([ 'context','lang', 'answerable'])

# Creating a function to change boolean label into 0 and 1

def prediction_change(dataset, column_name):
  dataset['labels'] = dataset[column_name] * 1
  return dataset

# Applying prediction_change method

# Training
train_ru_df = train_ru_df.map(lambda x: prediction_change(x, 'answerable'))
train_ja_df = train_ja_df.map(lambda x: prediction_change(x, 'answerable'))
train_fi_df = train_fi_df.map(lambda x: prediction_change(x, 'answerable'))
train_en_df = train_en_df.map(lambda x: prediction_change(x, 'answerable'))

#Validation
val_ru_df = val_ru_df.map(lambda x: prediction_change(x, 'answerable'))
val_ja_df = val_ja_df.map(lambda x: prediction_change(x, 'answerable'))
val_fi_df = val_fi_df.map(lambda x: prediction_change(x, 'answerable'))
val_en_df = val_en_df.map(lambda x: prediction_change(x, 'answerable'))

# Dropping unnecissary columns

# Train
train_ru_df = train_ru_df.remove_columns(['lang','answerable' ])
train_ja_df = train_ja_df.remove_columns(['lang','answerable'])
train_fi_df = train_fi_df.remove_columns(['lang','answerable'])
train_en_df = train_en_df.remove_columns(['lang','answerable'])

# Validation
val_ru_df = val_ru_df.remove_columns(['lang','answerable'])
val_ja_df = val_ja_df.remove_columns(['lang','answerable'])
val_fi_df = val_fi_df.remove_columns(['lang','answerable'])
val_en_df = val_en_df.remove_columns(['lang','answerable'])

"""# Roberta Model"""

#Loading ROBERTA
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification

# Loading pre-trained XLM-R
tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')
model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2) #Two labels for classification
model.gradient_checkpointing_enable()
#putting model to device for storage reasons
model.to(device)

"""## Tokenizer Functions"""

# Creating a tokenizer funtion

def tokenize(dataset):
    tokenized_dataset = tokenizer(dataset['context'],dataset['question'], padding=True, truncation=True, max_length=512)
    return tokenized_dataset

# Creating a tokenizer English funtion

def tokenize_en(dataset):
    tokenized_dataset = tokenizer(dataset['context'], padding=True, truncation=True, max_length=512)
    return tokenized_dataset

# Tokenizing context and questions

#Training
tokenized_train_ru = train_ru_df.map(tokenize, batched=True)
tokenized_train_ja = train_ja_df.map(tokenize, batched=True)
tokenized_train_fi  = train_fi_df.map(tokenize, batched=True)
tokenized_train_en = train_en_df.map(tokenize_en, batched=True)

#Validation
tokenized_eval_ru = val_ru_df.map(tokenize, batched=True)
tokenized_eval_ja = val_ja_df.map(tokenize, batched=True)
tokenized_eval_fi  = val_fi_df.map(tokenize, batched=True)
tokenized_eval_en = val_en_df.map(tokenize_en, batched=True)

"""## Metrics and Training Argumenets"""

# Training arguments

train_args = TrainingArguments(output_dir="my_trainer",
                                  eval_strategy="steps",
                                  num_train_epochs=8.0,
                                  per_device_train_batch_size=16,
                                  learning_rate=2e-5,
                                  eval_steps=500)

# Loading metrics
accuracy_metric = evaluate.load('accuracy')
precision_metric = evaluate.load('precision')
recall_metric = evaluate.load('recall')
f1_metric = evaluate.load('f1')

# Function to compute the metrics
def compute_metrics(eval_pred):
    outputs, labels = eval_pred
    predictions = np.argmax(outputs, axis=-1)
    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)
    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')
    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')
    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')

    return {
        'accuracy': accuracy['accuracy'],
        'precision': precision['precision'],
        'recall': recall['recall'],
        'f1': f1['f1']
    }

"""## Russian language

"""

# Checking the balance

le = LabelEncoder()
labels_encoded = le.fit_transform(tokenized_train_ru['labels'])
unique, counts = np.unique(labels_encoded, return_counts=True)
class_distribution = dict(zip(le.inverse_transform(unique), counts))
print(class_distribution)

#Oversampling minory class

df = pd.DataFrame(tokenized_train_ru)

# Counting the occurrences of each label
class_counts = df['labels'].value_counts()

majority_label = class_counts.idxmax()
minority_label = class_counts.idxmin()

n_minority_samples = class_counts[majority_label] - class_counts[minority_label]

# Oversampling the minority class
minority_samples = df[df['labels'] == minority_label]
oversampled_minority_samples = minority_samples.sample(n=n_minority_samples, replace=True, random_state=42)

# Combining datasets
balanced_df = pd.concat([df, oversampled_minority_samples])

balanced_dataset = Dataset.from_pandas(balanced_df)

# Checking balance
new_label_counts = balanced_df['labels'].value_counts()
print(new_label_counts)

# Initializing the trainer
trainer = Trainer(
    model=model,
    args=train_args,
    train_dataset= balanced_dataset,
    eval_dataset= tokenized_eval_ru,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer)

trainer.train()

# Print results
eval_results = trainer.evaluate()
print(f'Langugae ru: {eval_results}')

# Predictions
outputs = trainer.predict(tokenized_eval_ru)
logits = outputs.predictions
labels = outputs.label_ids
predictions = np.argmax(logits, axis=-1)

print("Predictions:", predictions)
print("True Labels:", labels)

# Confusion matrix
conf_matrix = confusion_matrix(labels, predictions)

#print("Confusion Matrix:")
#print(conf_matrix)

"""## Finnish Language

"""

#Checking the balance

le = LabelEncoder()
labels_encoded = le.fit_transform(tokenized_train_fi['labels'])
unique, counts = np.unique(labels_encoded, return_counts=True)
class_distribution = dict(zip(le.inverse_transform(unique), counts))
print(class_distribution)

#Oversampling minory class

df = pd.DataFrame(tokenized_train_fi)

# Counting the occurrences of each label
class_counts = df['labels'].value_counts()

majority_label = class_counts.idxmax()
minority_label = class_counts.idxmin()

n_minority_samples = class_counts[majority_label] - class_counts[minority_label]

# Oversampling the minority class
minority_samples = df[df['labels'] == minority_label]
oversampled_minority_samples = minority_samples.sample(n=n_minority_samples, replace=True, random_state=42)

# Combining datasets
balanced_df = pd.concat([df, oversampled_minority_samples])

balanced_dataset = Dataset.from_pandas(balanced_df)

# Checking balance
new_label_counts = balanced_df['labels'].value_counts()
print(new_label_counts)

trainer = Trainer(
    model=model,
    args=train_args,
    train_dataset= balanced_dataset,
    eval_dataset= tokenized_eval_fi,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer)

trainer.train()

eval_results = trainer.evaluate()
print(f'Langugae fi: {eval_results}')

# Predictions
outputs = trainer.predict(tokenized_eval_fi)
logits = outputs.predictions
labels = outputs.label_ids
predictions = np.argmax(logits, axis=-1)

print("Predictions:", predictions)
print("True Labels:", labels)

# Confusion matrix
conf_matrix = confusion_matrix(labels, predictions)

#print("Confusion Matrix:")
#print(conf_matrix)

"""## Japanese Language



"""

#Checking the balance

le = LabelEncoder()
labels_encoded = le.fit_transform(tokenized_train_ja['labels'])
unique, counts = np.unique(labels_encoded, return_counts=True)
class_distribution = dict(zip(le.inverse_transform(unique), counts))
print(class_distribution)

#Oversampling minory class

df = pd.DataFrame(tokenized_train_fi)

# Counting the occurrences of each label
class_counts = df['labels'].value_counts()

majority_label = class_counts.idxmax()
minority_label = class_counts.idxmin()

n_minority_samples = class_counts[majority_label] - class_counts[minority_label]

# Oversampling the minority class
minority_samples = df[df['labels'] == minority_label]
oversampled_minority_samples = minority_samples.sample(n=n_minority_samples, replace=True, random_state=42)

# Combining datasets
balanced_df = pd.concat([df, oversampled_minority_samples])

# Shuffle to mix oversampled data
balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

balanced_dataset = Dataset.from_pandas(balanced_df)

# Checking balance
new_label_counts = balanced_df['labels'].value_counts()
print(new_label_counts)

train_args = TrainingArguments(output_dir="my_trainer",
                                  eval_strategy="steps",
                                  num_train_epochs=3,
                                  per_device_train_batch_size=16,
                                  learning_rate=2e-5,
                                  eval_steps=500)

trainer = Trainer(
    model=model,
    args=train_args,
    train_dataset= balanced_dataset,
    eval_dataset= tokenized_eval_ja,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer)

trainer.train()

eval_results = trainer.evaluate()
print(f'Langugae ja: {eval_results}')

# Predictions
outputs = trainer.predict(tokenized_eval_ja)
logits = outputs.predictions
labels = outputs.label_ids
predictions = np.argmax(logits, axis=-1)

print("Predictions:", predictions)
print("True Labels:", labels)

# Confusion matrix
conf_matrix = confusion_matrix(labels, predictions)

print("Confusion Matrix:")
print(conf_matrix)